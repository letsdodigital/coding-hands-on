{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8tRG0qGWV3"
      },
      "source": [
        "# Workshop - Building a neural network\n",
        "\n",
        "Hello all - welcome to the final workbook for the DAIM course. Throughout this notebook, you will be introduced to more advanced aspects of Python. We will go through designing, testing, and evaluating a neural network from scratch in Python, which will give you insight into how to build basic machine learning models for other applications, and should give you a good starting point for further learning in the world of data science.\n",
        "\n",
        "This workbook will be run over several workshops, and will require time spent outside of the workshops to complete. We would encourage you to use the sources of online support that we have used in previous sessions to help you. The only way to learn how to code is through doing it and solving problems!\n",
        "\n",
        "By the end of this workshop, you should be able to:\n",
        " - Preprocess data for a machine learning model.\n",
        " - Adapt an existing model for your own dataset.\n",
        " - Understand the basics of evaluating a binary classifier in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1cDRatiHFpT"
      },
      "source": [
        "## Introduction - The Dataset\n",
        "\n",
        "The dataset that we will use for this workbook is [this one](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia/data): a dataset of 5,863 plain chest XRs which have been labelled by clinicians as either:\n",
        "\n",
        "1. Normal\n",
        "2. Pneumonia\n",
        "\n",
        "Have a read about the dataset via the link above and think about the following:\n",
        "\n",
        "1. What limitations might this labelling scheme have?\n",
        "2. Are there any sources of clinical bias that could be introduced?\n",
        "3. Can you think of any disadvantages of the image encoding they have used?\n",
        "\n",
        "If you would like to read more about this dataset, you can refer to [this publication](https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5).\n",
        "\n",
        "The reason we have chosen this dataset for this exercise is the small size (2GB) and simple labelling. Many medical machine learning datasets run into the terabyte range, and have many labels associated with each datapoint. Starting with more basic datasets will give you a better insight into how these models actually work.\n",
        "\n",
        "To download the model, execute the following commands in the Colab workbook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvCVtPbZI84t"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "!unzip chest-xray-pneumonia.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHVLrQVoJBkH"
      },
      "source": [
        "If these commands are successful, you should see lots of lines of terminal output as the `unzip` command unzips each of the ~5000 images.\n",
        "\n",
        "*NB if you are running these commands locally, enter them into your terminal window without the preceding \"!\"*\n",
        "*The \"!\" tells Colab to run this command as a terminal command on the server that we are running, rather than as a line of Python code.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNWCY7YLeazR"
      },
      "source": [
        "## Importing the necessary packages\n",
        "\n",
        "This workbook uses a few external libraries to make our work easier and to provide high-level *abstraction* away from the way that machine learning works \"under the hood\". Run the following code to import all the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG1gIqWeerep"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "import sklearn.metrics as metrics\n",
        "from torchvision.transforms import functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vwRrdfhJDuw"
      },
      "source": [
        "# Stage One - Inspecting the dataset\n",
        "\n",
        "We've downloaded the data - what form is it in? This will be vital to understanding how to preprocess it into a form that a neural network can be trained on.\n",
        "\n",
        "In any dataset, there will be the raw data (images, time-series data, etc.) and semantic labels. The term \"semantic\" in this context refers to giving data \"meaning\" - your computer doesn't know what the image data contains unless you label it.\n",
        "\n",
        "The labels describe the attribute that you want to predict with your model. Common formats for these include:\n",
        "\n",
        "1. Raw data sorted into directories\n",
        "2. A large table detailing the datapoints with their associated semantic labels, stored as a CSV file.\n",
        "\n",
        "Which of the above categories does our data, `chest_xray`, fall in to? To see the data, select the folder icon on the left-hand side of the screen, or navigate to the directory that you are running this workbook from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9iAoirPE6F"
      },
      "source": [
        "## How machine learning datasets are split\n",
        "\n",
        "This dataset is split into 3 folders: train, test and validation. For a recap from the seminar:\n",
        "<!-- TODO: make sure you add this to the seminars -->\n",
        "\n",
        "1. Training data is the largest partition of the dataset and is what is used to update the weights of the model during training.\n",
        "2. Testing data is used to test the data at the end of training - a finals exam. The model never \"sees\" any of this data at any point during training.\n",
        "3. Validation - this data is used to evaluate the model during training. The model is not trained on this data.\n",
        "\n",
        "If you are collecting this data in the real world, the dataset will often not be split like this, and it is the job of the data scientist to partition it appropriately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXJpt5oxLIVg"
      },
      "source": [
        "## Exercise 1 - Opening an image\n",
        "\n",
        "Let's start by displaying a few images from the dataset. Open and display the first few normal images from the `chest_xray/test` directory. *Hint: use the os.listdir() and os.path.join() methods.*\n",
        "\n",
        "*NB: ignore the* `chest_xray/chest_xray` *subdirectory for the rest of the practical.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgNaGWVCLw8w"
      },
      "outputs": [],
      "source": [
        "# Type your code here..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gISYjjVuL9dd"
      },
      "source": [
        "### Solution 1\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    target_dir = \"chest_xray/test/NORMAL\"\n",
        "    normal_image_paths = os.listdir(target_dir)\n",
        "    for path in normal_image_paths[:3]:\n",
        "        full_path = os.path.join(target_dir, path)\n",
        "        im = Image.open(full_path)\n",
        "        display(im)\n",
        "\n",
        "    \"\"\"\n",
        "    Using os.listdir is more reusable than simply copy-pasting the desired image file\n",
        "    paths into the Image.open() command.\n",
        "    \"\"\"\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4pYS97bOKq1"
      },
      "source": [
        "## Exercise 2\n",
        "\n",
        "Next, using your code from the previous exercise, create a function that will show a certain number of images from either the normal or pneumonia directories. Use this to display some of the pneumonia XRs from the test dataset. The number of images requested and the label should be passed as arguments.\n",
        "\n",
        "*Try to think about error handling when designing this function - when might the function fail?*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Type your code here..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution 2\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    def show_images(label, num_images=3):\n",
        "\n",
        "        target_dir = \"chest_xray/test/{}\".format(label)\n",
        "        image_paths = os.listdir(target_dir)\n",
        "\n",
        "        if num_images > len(image_paths):\n",
        "            raise Exception(f\"Too many images ({num_images}) requested!\")\n",
        "\n",
        "        for path in image_paths[:num_images]:\n",
        "            full_path = os.path.join(target_dir, path)\n",
        "            im = Image.open(full_path)\n",
        "            display(im)\n",
        "\n",
        "    show_images(\"PNEUMONIA\", 2)\n",
        "    # show_images(\"PNEUMONIA\", 100000) # This results in an error.\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chemxhv7yH9E"
      },
      "source": [
        "**Solution Explanation**\n",
        "\n",
        "Using string formatting on line 3 here allows for clear insertion of the desired label\n",
        "into the target directory. Appending the strings with \"+\" would also be appropriate.\n",
        "Use of \"os.path.join\" is good practice, rather than stitching together the string manually with \"/\"\n",
        "as it is less error prone.\n",
        "\n",
        "Always think about catching errors - what if the number of images\n",
        "requested was larger than the number available in the directory?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlNW0DyORluj"
      },
      "source": [
        "## Exercise 3\n",
        "\n",
        "Write a simple script which reports the total number of images in each partition (test/train/validation) and each label (normal/pneumonia) of the dataset.\n",
        "\n",
        "*NB: again, ignore the* `chest_xray/chest_xray` *subdirectory.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Type your code here..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution 3\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    def report_dir(partition, file_path=\"chest_xray\", labels=[\"NORMAL\", \"PNEUMONIA\"]):\n",
        "\n",
        "        file_path = os.path.join(file_path, partition)\n",
        "\n",
        "        for label in labels:\n",
        "            imgs = os.path.join(file_path, label)\n",
        "            img_num = len(os.listdir(imgs))\n",
        "            print(f\"\\t{label}: {img_num}\")\n",
        "\n",
        "    print(\"Training data: \")\n",
        "    report_dir(\"train\")\n",
        "\n",
        "    print(\"Testing data: \")\n",
        "    report_dir(\"test\")\n",
        "\n",
        "    print(\"Validation data: \")\n",
        "    report_dir(\"val\")\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQmVyVMxZmMu"
      },
      "source": [
        "**Solution breakdown**\n",
        "\n",
        "There is no right/wrong way to write this code, and there are multiple ways to\n",
        "achieve the task in the exercise. In general, code should be duplicated as little\n",
        "as possible whilst still maintaining clarity about what it does. It is very easy\n",
        "to obfuscate code with the single goal of making it take up fewer lines.\n",
        "\n",
        "As the structure of each partition directory is identical, it makes sense to write a\n",
        "report_dir function which prints the report for any of the three directory.\n",
        "\n",
        "I have passed the file_path and labels as arguments to make the function\n",
        "reusable - what if we had a similar dataset for NORMAL/PE which was\n",
        "called chest_ct?\n",
        "\n",
        "This gives you an idea of the overall size of the dataset we are working with. We can see from the output of this function that we have many more abnormal X-rays than normal ones in the training partition - how might this affect training?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2b4PW_IU2Js"
      },
      "source": [
        "# Stage 2 - Preprocessing\n",
        "\n",
        "Preprocessing refers to preparing the data for training a machine learning system. It is often the most time-consuming part of designing a machine learning system.\n",
        "\n",
        "All machine learning training methods require data to be in a certain format. This is because the model's input layer has a certain shape, which has to be matched by our input image. For images, these constraints can include:\n",
        "\n",
        "1. **Input image size** - in our case, most images are far higher resolution than it would be possible to build a convolutional neural network to process. You will be able to test this later in the practical.\n",
        "2. **Input image dimensions** - often, networks require square images to make computations easier.\n",
        "3. **Input image channels** - often, images need to be greyscale. Luckily, this is not an issue for us.\n",
        "\n",
        "Over the next few exercises, we will build up a function that is able to manage the above, before considering later stages of pre-processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oj14mlNWwjM"
      },
      "source": [
        "## Exercise 4\n",
        "\n",
        "Let's consider a single image to make the process of code design easier. Write a function that takes an image filepath, opens the image, and appropriately center crops it to a set of dimensions that is passed as an argument. All images returned from the function must be square.\n",
        "\n",
        "Hint: use [this StackOverflow issue](https://stackoverflow.com/questions/16646183/crop-an-image-in-the-centre-using-pil) to help you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqxt26UMWvWv"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nizMkP8XY3y"
      },
      "source": [
        "## Solution 4\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "  def crop_and_scale(img, target_size):\n",
        "\n",
        "    # Crop the center of the image\n",
        "    height, width = img.size\n",
        "    square_size = min(height, width)\n",
        "    img = F.center_crop(img, square_size)\n",
        "\n",
        "    # Resize the image\n",
        "    resized_im = F.resize(img, (target_size, target_size))\n",
        "    return resized_im\n",
        "\n",
        "\n",
        "    test_im = \"chest_xray/train/PNEUMONIA/person986_bacteria_2913.jpeg\"\n",
        "    im = Image.open(test_im)\n",
        "\n",
        "    im = crop_and_scale(im, 256)\n",
        "    display(im)\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRUBa5KSZvra"
      },
      "source": [
        "**Solution Breakdown**\n",
        "\n",
        "We decided to import and use a function from the Torch library here, as\n",
        "it is simple and will cover cases that might cause errors in a simple\n",
        "implementation. Torch is a machine learning library, and the presence of\n",
        "this function in the library shows how common an issue this is for\n",
        "data scientists.\n",
        "\n",
        "As we want all images from the function to be square, there is no reason\n",
        "to pass in 2D dimensions to the function, as they will always be the\n",
        "same e.g. (64, 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B_PHd1eZ3Yq"
      },
      "source": [
        "## Exercise 5 - Specifying constraints\n",
        "\n",
        "Let's extend our preprocessing function. The machine learning model will be accepting the images in array form. Each image must have:\n",
        "\n",
        "1. Only 1 channel (greyscale)\n",
        "2. All values must be between `0.0` and `1.0`\n",
        "\n",
        "Use your test image and preprocessing function from the last code block and inspect the images in NumPy array format to confirm that they meet the two constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KXT5yH_acYr"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5tzIumBac0J"
      },
      "source": [
        "## Solution 5\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    test_im = \"chest_xray/train/PNEUMONIA/person986_bacteria_2913.jpeg\"\n",
        "    im = Image.open(test_im)\n",
        "\n",
        "    im = crop_and_scale(im, 256)\n",
        "    display(im)\n",
        "\n",
        "    im_arr = np.array(im) # Convert to Numpy Array\n",
        "\n",
        "    print(im_arr.shape)\n",
        "    print(im_arr.max(), im_arr.min())\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2xGopu2aeYm"
      },
      "source": [
        "**Solution Breakdown**\n",
        "\n",
        "The image has the appropriate shape and dimensions, but has a max value of much higher than 1.0. This demonstrates that it is still in 8 bit integer format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAarRwiDbhui"
      },
      "source": [
        "## Exercise 6\n",
        "\n",
        "Appropriately modify the preprocessing function to correct for the problem identified in the previous exercise and to make the function return NumPy arrays rather than PIL Images.\n",
        "\n",
        "*NB: Some images in this dataset are opened as colour images (i.e. with 3 channels). How can you prevent this from affecting the output of the function?*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BWRCWurb0eB"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okBRokZfb0Er"
      },
      "source": [
        "## Solution 6\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    def crop_and_scale(img, target_size):\n",
        "\n",
        "        # Crop the center of the image\n",
        "        height, width = img.size\n",
        "        square_size = min(height, width)\n",
        "        img = F.center_crop(img, square_size)\n",
        "\n",
        "        # Resize the image\n",
        "        resized_im = F.resize(img, (target_size, target_size))\n",
        "        grayscale_im = ImageOps.grayscale(resized_im)\n",
        "\n",
        "        return np.array(grayscale_im) / 255.0\n",
        "\n",
        "    test_im = \"chest_xray/train/PNEUMONIA/person986_bacteria_2913.jpeg\"\n",
        "    im = Image.open(test_im)\n",
        "\n",
        "    im_arr = crop_and_scale(im, 256)\n",
        "\n",
        "    # Code to convert from array back to PIL Image:\n",
        "    im = Image.fromarray((im_arr * 255.0).astype(np.uint8))\n",
        "    display(im)\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp8EWV6zb2dE"
      },
      "source": [
        "**Solution breakdown**\n",
        "\n",
        "The image is converted into a NumPy array with `np.array()` and scaled down by `255.0`, to convert from 8 bit integers (0-255) to floating point numbers (0.0-1.0). This also ensures that the numbers are \"normalised\" - within a specified range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_UQwRkTfLOB"
      },
      "source": [
        "# Stage 3 - Batching and Sampling\n",
        "\n",
        "A machine learning model accepts data in batches. A batch is a small collection of images that are used for one step of training. Every image is passed through the network in its current state, and then the 'errors' are averaged out between the images in the batch to update the weights. This is important to know because:\n",
        "\n",
        "1. The larger the batch, the more accurate the estimate of the 'direction' the model needs to go in to reduce its error rate.\n",
        "\n",
        "However, usually a batch needs to be loaded into RAM from the disk/SSD for it to be processed. A batch of uncompressed image data can get very large, very fast!\n",
        "\n",
        "*Side task - how many bytes of data would a batch of 2048 images at 512x512 pixels be?*\n",
        "\n",
        "Before we create our batching function, we have to consider how we are going to sample data for each batch. Ideally, each batch should contain similar amounts of each data from each class - in our situation, normal/pneumonia.\n",
        "\n",
        "However, our dataset is **unbalanced** - there is more pneumonia data than normal data. In order to combat this, we will **oversample** the normal data - the network will \"see\" the normal data more times than the pneumonia data. This has advantages and disadvantages:\n",
        "\n",
        "1. It is easy to do.\n",
        "2. It can lead to overfitting. If the dataset was extremely unbalanced, the model may start to interpret normal anatomical variations as pneumonia, as it has not had adequate exposure to normal data.\n",
        "\n",
        "Before oversampling data, you should make sure that there is enough diversity in the dataset to allow the model to learn the characteristics that you want.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x24BuFWnhIA_"
      },
      "source": [
        "## The process of training\n",
        "\n",
        "During the training process, the model will \"see\" each data point multiple times. When creating the batches, we will use random sampling to ensure good diversity between each batch - no two batches should be the same. This will help the model gain a good average of the \"direction\" it should move in over successive batches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>Exercise 7a - Getting the full dataset</h2>\n",
        "\n",
        "Before we sample random batches, we need the list that tells us where we can sample the images from. This will come in the form of a list of filepaths, which point to the images in the training dataset that we can sample.\n",
        "\n",
        "For this exercise, create a function called `get_filepaths` which returns a list of all of the filepaths to each of the available images in the given dataset partition (i.e. `train`, `test`, `val`)\n",
        "\n",
        "Print the first few filepaths to briefly check your work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdOgdA46wZKK"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6No8BJVAwZa2"
      },
      "source": [
        "## Solution 7a\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    def get_filepaths(partition=\"train\"):\n",
        "\n",
        "        root_path = \"chest_xray\"\n",
        "        labels = [\"NORMAL\", \"PNEUMONIA\"]\n",
        "\n",
        "        file_paths = []\n",
        "        for i, label in enumerate(labels):\n",
        "            path = os.path.join(root_path, partition, label)\n",
        "            image_fns = [os.path.join(path, x) for x in os.listdir(path)]\n",
        "\n",
        "            file_paths += image_fns\n",
        "\n",
        "        return file_paths\n",
        "\n",
        "    fps = get_filepaths()\n",
        "    print(fps[:5])\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLV_qQynwbRi"
      },
      "source": [
        "**Solution Explanation**\n",
        "\n",
        "This function makes use of the `os` library and its directory methods. This allows us to efficiently collect all the data we need - `os.listdir()` returns a list of all the files in that directory, and `os.path.join()` efficiently \"stitches\" together two filepaths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm7tqkzmhENO"
      },
      "source": [
        "## Exercise 7b - Batching data\n",
        "\n",
        "Write a function that creates batches from a specified directory (test/train/val). Pass the filepaths for the dataset that you generate with `get_filepaths()` to the function. Make sure you use random sampling for each batch.\n",
        "\n",
        "1. **Use online sources of information to help you.** StackOverflow can be very helpful for building functions like this.\n",
        "2. Make sure you think about error handling when designing the function. What combination of input parameters would cause the function to fail?\n",
        "3. Use the `crop_and_scale` function from Exercise 6 to preprocess the images.\n",
        "4. Use ideas from the previous exercises to help you get started.\n",
        "5. It is helpful to plan each step you will need to include for the function with comments.\n",
        "\n",
        "The function should be called `make_batch`. The function is specified below:\n",
        "\n",
        "```python\n",
        "def make_batch(img_filepaths, im_size, batch_size):\n",
        "    \"\"\"\n",
        "    Returns a randomly sampled batch of images from the chest_xray dataset for training.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    img_filepaths : lst\n",
        "        List of image filepaths to sample from.\n",
        "    im_size : int\n",
        "        The square image dimension of the images in the batch.\n",
        "    batch_size : int\n",
        "        The desired size of the batch.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.array\n",
        "          Batch of images, stored in a 3D array. Shape: (batch_size, im_size, im_size)\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> make_batch(\"NORMAL\", 256, 4).shape\n",
        "    (4, 255, 255)\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "*NB: This is called a docstring, and is a way to document what your Python function does. It  should provide a description of what your function does and can be shown in code editors like VS Code when you hover over a function name.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br_Q4jQEnEM-"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RUBqtXum_xx"
      },
      "source": [
        "##  Solution 7b\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    def make_batch(image_filepaths, im_size, batch_size):\n",
        "\n",
        "        # Randomly sample image filepaths for the batch.\n",
        "        batch_paths = random.sample(image_filepaths, batch_size)\n",
        "\n",
        "        batch = np.zeros((batch_size, im_size, im_size))\n",
        "        for i, path in enumerate(batch_paths):\n",
        "            im = Image.open(path)\n",
        "            batch[i] = crop_and_scale(im, im_size)\n",
        "\n",
        "        return batch\n",
        "\n",
        "    train_fps = get_filepaths(\"train\")\n",
        "    batch = make_batch(train_fps, 256, 4)\n",
        "\n",
        "    # Inspect the images.\n",
        "    im = Image.fromarray((batch[3] * 255.0).astype(np.uint8))\n",
        "    display(im)\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIy_JsRwrMrg"
      },
      "source": [
        "**Solution breakdown**\n",
        "\n",
        "This function randomly samples a set of filepaths from the dataset and returns them as a batch, after cropping and scaling them appropriately. The batch array is created first as this will make the code faster, as the array is \"preallocated\" - instead of adding things to a list, you tell NumPy exactly how big the array will be before the `for` loop. This allows it to not have to adjust the amount of memory it needs for the batch as it goes along."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXKMlzLLsMCE"
      },
      "source": [
        "## Encoding Labels\n",
        "\n",
        "We now have a way to feed the neural network batches of data. However, the neural network does currently not know what each image represents. In order to do this, we have to preprocess the labels for each batch too.\n",
        "\n",
        "Our labels for this dataset are \"PNEUMONIA\" and \"NORMAL\" - these are strings, discrete data. In order for the network to train on these labels, we have to encode the labels into numbers. This is because the network calculates the error between the output of the network and the labels we provide.\n",
        "\n",
        "For our network, we will encode 0.0 as \"NORMAL\", and 1.0 as \"PNEUMONIA\". This is a **label encoding**, as we are assigning integer values to each label - 0 or 1, NORMAL or PNEUMONIA.\n",
        "\n",
        "## Difference between label and one-hot encoding\n",
        "\n",
        "A large proportion of encoding for image datasets in machine learning occurs as one-hot encoding. This sets a 1 for features that are present, and 0 for ones that are not. For example:\n",
        "\n",
        "```\n",
        "Data: Image of a cat\n",
        "Labels: [dog, cat, fish, bear]\n",
        "Encoding: [0, 1, 0, 0]\n",
        "```\n",
        "\n",
        "For our network, this would be:\n",
        "```\n",
        "Image: Pneumonia\n",
        "Labels: [NORMAL, PNEUMONIA]\n",
        "Encoding: [0, 1]\n",
        "```\n",
        "\n",
        "We will use label encoding for simplicity - the network will only have one output neuron:\n",
        "\n",
        "```\n",
        "Image: Pneumonia\n",
        "Labels: [NORMAL, PNEUMONIA]\n",
        "Encoding: [1]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfw_scs6sgBb"
      },
      "source": [
        "## Exercise 8 - Adding labels\n",
        "\n",
        "Add label generation to the `make_batch` function. An updated docstring for what the function should return is given below:\n",
        "\n",
        "```python\n",
        "def make_batch(partition, im_size, batch_size):\n",
        "    \"\"\"\n",
        "    Returns an equally balanced batch of images from the chest_xray dataset for training.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    img_filepaths : lst\n",
        "        List of image filepaths to sample from.\n",
        "    im_size : int\n",
        "        The square image dimension of the images in the batch.\n",
        "    batch_size : int\n",
        "        The desired size of the batch.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.array\n",
        "          Batch of images, stored in a 3D array. Shape: (batch_size, im_size, im_size)\n",
        "    np.array\n",
        "          Batch of labels, label encoded. Shape: (batch_size)\n",
        "    \"\"\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwedUzF87yvL"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9-8AI8Q7xyg"
      },
      "source": [
        "## Solution 8\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    def make_batch(image_filepaths, im_size, batch_size):\n",
        "\n",
        "        # Randomly sample image filepaths for the batch.\n",
        "        batch_paths = random.sample(image_filepaths, batch_size)\n",
        "\n",
        "        batch = np.zeros((batch_size, im_size, im_size))\n",
        "        labels = np.zeros((batch_size))\n",
        "\n",
        "        for i, path in enumerate(batch_paths):\n",
        "            im = Image.open(path)\n",
        "            batch[i] = crop_and_scale(im, im_size)\n",
        "            labels[i] = \"PNEUMONIA\" in path\n",
        "\n",
        "        return batch, labels\n",
        "\n",
        "    train_fps = get_filepaths(\"train\")\n",
        "    batch, labels = make_batch(train_fps, 256, 4)\n",
        "\n",
        "    print(labels)\n",
        "\n",
        "    # Inspect an image from the batch.\n",
        "    i = 0\n",
        "    im = Image.fromarray((batch[i] * 255.0).astype(np.uint8))\n",
        "    display(im)\n",
        "    print(\"Label: {}\".format(labels[i]))\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEysexTP8rtI"
      },
      "source": [
        "**Solution explanation**\n",
        "\n",
        "There are many ways to do this within this function. In order to make the code concise, we detect if the string \"PNEUMONIA\" appears anywhere in the filepath. If it does, we set the label to `1.0` (`True`), else it is set to `0` (`False`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFJx12Pd9ygL"
      },
      "source": [
        "# Stage 4 - Creating the model\n",
        "\n",
        "We are now at the stage that we can create our model. The model that we will use in this seminar is a **convolutional neural network**. These networks start with convolutional layers, which \"look\" at small regions across the image with kernels, followed by dense neural network layers. These gradually reduce towards to the final layer, which contains a single neuron - this will output a number between 0 and 1, indicating the prediction of `NORMAL` or `PNEUMONIA`.\n",
        "\n",
        "To create the model, we will be using the `keras` library, which is part of TensorFlow, Google's machine learning framework.\n",
        "\n",
        "Often, researchers and data scientists will adapt exist models to fit their needs. A good example of this is UNet, a type of convolutional neural network (autoencoder) that has been used for multiple different biomedical applications.\n",
        "\n",
        "To give you a feeling for what this process is like, there is a script below which contains the fictional model training code for a model from an ornithologist that can distinguish between finches and swallows. Throughout this stage of the notebook, you will adapt the code to suit our medical application.\n",
        "\n",
        "The code is shown below:\n",
        "\n",
        "```python\n",
        "# FINCH-NET Code. MIT Licence, 2024. Code by Dr Ala Wing\n",
        "from tensorflow import keras\n",
        "\n",
        "img_size = 256\n",
        "\n",
        "# The shape of each image in the batch\n",
        "input_shape = (img_size, img_size, 1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=input_shape),\n",
        "    keras.layers.Conv2D(128, 5, activation='relu'),\n",
        "    keras.layers.MaxPooling2D(),\n",
        "    keras.layers.Conv2D(512, 3, activation='relu'),\n",
        "    keras.layers.MaxPooling2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "train_gen = batch_generator(\n",
        "    total_size=1024,\n",
        "    batch_size=8,\n",
        "    image_crop_region=(img_size,img_size),\n",
        "    data_name=\"train\"\n",
        ")\n",
        "\n",
        "val_gen = batch_generator(\n",
        "    total_size=1024,\n",
        "    batch_size=8,\n",
        "    image_crop_region=(img_size,img_size),\n",
        "    data_name=\"val\"\n",
        ")\n",
        "\n",
        "# Label structure: [\"Finch\", \"Swallow\"]\n",
        "\n",
        "model.fit(\n",
        "    train_gen,\n",
        "    epochs=250,\n",
        "    steps_per_epoch=1024 / 8,\n",
        "    validation_data=val_gen,\n",
        "    validation_batch_size=1,\n",
        "    validation_steps=32 / 8\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGiU5dvv-t9r"
      },
      "source": [
        "## Explanation of the model architecture\n",
        "\n",
        "The first half of the model has convolutional (`Conv2D`) and max pooling (`MaxPooling2D`) layers.\n",
        "\n",
        "1. **`Conv2D`**\n",
        "\n",
        "This layer is declared like this:\n",
        "\n",
        "```python\n",
        "keras.layers.Conv2D(1024, 5, activation='relu'),\n",
        "```\n",
        "\n",
        "The parameter `1024` refers to the number of kernels (or filters) that will be used in this layer. Much like different kernels can extract edges or blur images eariler in the course, each kernel here is \"learnt\" and extracts different information from the image.\n",
        "\n",
        "The parameter `5` refers to the kernel size. It refers to the square dimension of the kernel, and therefore how much of the image it \"looks\" at during each convolution (e.g. a 5x5 pixel area).\n",
        "\n",
        "The parameter `activation='relu'` refers to the activation function of the layer. This describes the non-linear function that the neuron in the layer will use. Reasons for selecting different activation functions is partly outside the scope of this course - ReLU layers are commonly used within machine learning.\n",
        "\n",
        "\n",
        "2. **`MaxPooling2D`**\n",
        "\n",
        "This layer reduces the dimensions of the input image by half. It does this by \"looking\" at 2x2 groups of pixels across the whole image and selecting the largest value. This allows the model to gradually downsample the image, allowing the layers to become smaller as the model extracts higher-order data.\n",
        "\n",
        "3. **`keras.layers.Flatten()`**\n",
        "\n",
        "This layer flattens 2D collections of neurons into a 1D array, which is necessary before the `Dense` layers.\n",
        "\n",
        "4. **`keras.layers.Dense(128, activation='relu')`**\n",
        "\n",
        "`Dense` layers are flat layers of fully connected neurons, which are a staple layer for building neural networks. They are fully connected, so that they can \"see\" data from all over the image, unlike the convolution layers, which could only \"see\" data from small regions.\n",
        "\n",
        "The `128` parameter refers to the number of neurons that the layer has. More neurons means that the network can represent more data, but are slower to run and take up more memory. More neurons can also increase the risk of overfitting.\n",
        "\n",
        "The final layer is shown below:\n",
        "\n",
        "```python\n",
        "keras.layers.Dense(1, activation='sigmoid')\n",
        "```\n",
        "\n",
        "It has 1 neuron and has a sigmoid activation function. You may remember the shape of sigmoid curves from the oxygen dissociation curves from haemoglobin from physiology - here it ensures that the output neuron only displays a number between 0 and 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vhql_I-CkkA"
      },
      "source": [
        "## Exercise 9 - Model summary\n",
        "\n",
        "Declare the FINCH-NET model and print a summary of it's structure using the code above.\n",
        "\n",
        "Try changing the parameters of the model and running the code again - what happens to overall model parameter number? Which layers have the largest impact on overall parameter number and model size?\n",
        "\n",
        "What are the main differences between the input for our network and the FINCH-NET network? How might we have to change it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxDzBox0Cv53"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX1loP1NCwVi"
      },
      "source": [
        "## Solution 9 \n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    img_size = 256\n",
        "\n",
        "    # The shape of each image in the batch\n",
        "    input_shape = (img_size, img_size, 1)\n",
        "\n",
        "    # Create the model\n",
        "    model = keras.Sequential([\n",
        "        keras.Input(shape=input_shape),\n",
        "        keras.layers.Conv2D(128, 5, activation='relu'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        keras.layers.Conv2D(512, 3, activation='relu'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(32, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.summary()\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUuTkM7TIJN6"
      },
      "source": [
        "**Solution Explanation**\n",
        "\n",
        "The layer that has the largest effect on the size of the model is the first `Dense` layer, as this interacts with the large, flattened convolutional layer.\n",
        "\n",
        "The size of the input image is `(size, size, 1)`, which is different to our images, which have no last channel - `(size, size)`. This is a common feature of input layers of neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjhWM3dxD0b-"
      },
      "source": [
        "# Stage 5 - Compiling the model\n",
        "\n",
        "Next, the model must be compiled. This refers to the process of setting the parameters of how the model will be trained, and what the model training functions will report back to us during training. The compliation code for FINCH-NET is shown below:\n",
        "\n",
        "```python\n",
        "model.compile(\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "```\n",
        "\n",
        "1. `keras.losses.BinaryCrossentropy()`\n",
        "\n",
        "This declares the **loss function**, which is the function with which the network determines how far its prediction is from the labels. Many different loss functions can be selected for different reasons - this is beyond the scope of this course. The most common are categorical or binary crossentropy.\n",
        "\n",
        "Crossentropy measures the difference between two probability distributions. This allows the model to objectively measure how incorrect it is. This allows it to determine how aggressively to correct its weights. Working code examples are given below if you are interested:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTco4sdbK4tE"
      },
      "outputs": [],
      "source": [
        "from math import log\n",
        "\n",
        "def binary_crossentropy(predicted, true_val):\n",
        "    return true_val * log(predicted) + (1 - true_val) * log(1 - predicted)\n",
        "\n",
        "# Image is pneumonia, model predicts high probability of pneumonia\n",
        "print(\"Model is correct: \", binary_crossentropy(0.99, 1.0))\n",
        "\n",
        "# Image is pneumonia, model predicts  low probability of pneumonia\n",
        "print(\"Model is wrong: \", binary_crossentropy(0.05, 1.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOm-VHJMLwPH"
      },
      "source": [
        "2. `optimizer=\"adam\"`\n",
        "\n",
        "This declares the optimiser that the model uses to optimise its weights. How different optimisers work is beyond the scope of this course, but different optimisers cause the weights to be explored differently.\n",
        "\n",
        "Thinking back to the ball on a hill analogy, the optimiser controls where the ball starts, and the rules by which it rolls across the landscape.\n",
        "\n",
        "3. `metrics=[\"accuracy\"]`\n",
        "\n",
        "This list determines the model evaluation metrics that are reported back to us during training. Unfortunately, accuracy does not sum up the full performance of a model - we will discuss this during the seminars and later in this workbook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sc1Ss7sMuQA"
      },
      "source": [
        "# Stage 6 - Generating batches for the FINCH-NET model\n",
        "\n",
        "Looking at the FINCH-NET code, the `model.fit` method is passed `train_gen`, which is generated from the function `batch_generator`, to which we do not have access. However, the function name suggests that it is a **generator**.\n",
        "\n",
        "**Generators** are Python objects that are similar functions, but can return data \"on the fly\" when they are being executed without returning by using the `yield` keyword.\n",
        "\n",
        "They are commonly used when building memory-intensive code, as they allow small chunks of data to be loaded, one at a time - like batches!\n",
        "\n",
        "Usually, you cannot load your entire training dataset into RAM from your disk during training. Here, generators are helpful in providing the model with small chunks of data at a time, to prevent all of the training data being transferred into memory in one go. A simple example of a generator that generates incrementing powers of 2 is given below to give you an idea of how they work.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jdmb-7rQOvyC"
      },
      "outputs": [],
      "source": [
        "def powers_of_two(length):\n",
        "    for i in range(length):\n",
        "        yield 2 ** i\n",
        "\n",
        "gen = powers_of_two(10)\n",
        "\n",
        "for number in gen:\n",
        "    print(number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjreEvWnQv05"
      },
      "source": [
        "In addition to this, each image within a batch of the FINCH-NET training data has the following shape:\n",
        "\n",
        "```python\n",
        "# The shape of each image in the batch\n",
        "input_shape = (img_size, img_size, 1)\n",
        "```\n",
        "\n",
        "This is different to the return shape of our current `make_batch` function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re04RNK1Rdef"
      },
      "source": [
        "## Exercise 10 - Creating the training generator\n",
        "\n",
        "Wrap the existing `make_batch` function in a seperate function called `batch_generator`. It should have the following features:\n",
        "\n",
        "1. The array shape of each image of the batch should match the image shape of the FINCH-NET input. (*Hint: expand_dims*)\n",
        "2. Use the yield keyword to create each batch.\n",
        "\n",
        "We don't have access to the original FINCH-NET `batch_generator` function, but the team have kindly provided the docstring for the function. Use this to help you design your wrapper. Only the outputs of the function must match, as this is what their Keras CNN is expecting - feel free to set whichever input parameters you think are most appropriate.\n",
        "\n",
        "\n",
        "```python\n",
        "def batch_generator()\n",
        "    \"\"\"\n",
        "    Returns a generator to generate all training data for an epoch of training for FINCH-NET.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    total_size : int\n",
        "        The total size of the training dataset for this epoch.\n",
        "    batch_size : int\n",
        "        The desired size of the batch.\n",
        "    image_crop_region : tuple\n",
        "        The square region to crop. Birds are always postition centrally in the image.\n",
        "    data_name : str\n",
        "        The name of the dataset to pull the bird images from.\n",
        "\n",
        "    Yields\n",
        "    -------\n",
        "    np.array\n",
        "          Batch of images for training. Shape: (batch_size, im_size, im_size, 1)\n",
        "    np.array\n",
        "          Batch of labels, label encoded. Shape: (batch_size)\n",
        "    \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOB_CF-tTsQD"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN6cWiplTsk5"
      },
      "source": [
        "## Solution 10\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    def batch_generator(batch_num, batch_size, partition, im_size):\n",
        "\n",
        "        # Get the filepaths that can be sampled\n",
        "        dataset_fps = get_filepaths(partition)\n",
        "        batch, labels = make_batch(train_fps, 256, 4)\n",
        "\n",
        "        for i in range(batch_num):\n",
        "            batch, labels = make_batch(dataset_fps, im_size, batch_size)\n",
        "\n",
        "            # Expand the dims along the 3rd axis (4th dimension)\n",
        "            # to make the batch compatible with the model\n",
        "            batch = np.expand_dims(batch, axis=3)\n",
        "\n",
        "            yield batch, labels\n",
        "\n",
        "    example_gen = batch_generator(\n",
        "        batch_num=1,\n",
        "        batch_size=4,\n",
        "        partition=\"train\",\n",
        "        im_size=64\n",
        "    )\n",
        "\n",
        "    for batch, labels in example_gen:\n",
        "        print(batch.shape)\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSpUrirGUve7"
      },
      "source": [
        "**Solution explanation**\n",
        "\n",
        "We have used the `np.expand_dims()` method to make the shape of our batch align with the one from the FINCH-NET example. This is a common modification that has to be done for inputting data into neural networks.\n",
        "\n",
        "We use the `yield` keyword to yield the images and labels for each batch of training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UvE_wMFVLwb"
      },
      "source": [
        "# Stage 7 - Training the model\n",
        "\n",
        "We have finally reached the point where we can train the model, based on the FINCH-NET code above. This will utilise all the code we have written so far to feed the model for training.\n",
        "\n",
        "Training is split into mutliple stages:\n",
        "\n",
        "1. **Batch Step**\n",
        "\n",
        "This is the smallest division of training that we control - the model creates a prediction for every image in the batch, and the weights are updated based on the average error across all of the image predictions.\n",
        "\n",
        "2. **Epoch**\n",
        "\n",
        "An epoch of training contains a certain number of steps per epoch. Batch steps are repeated to train the model.\n",
        "\n",
        "Training occurs for a specified number of epochs. When using a generator, you must make sure that the generators can create the total amount of data that will be needed over the entire training period: `batch_size * steps_per_epoch * epoch_number`.\n",
        "\n",
        "## Exercise 11 - Adapting FINCH-NET for pneumonia classification\n",
        "\n",
        "Use the FINCH-NET code and the generator from the previous exercise to train the neural network. Experiment with reducing the size of the model - does this improve the training time or decrease the accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1N9KLqLVmnA"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTf2RjzmVm8A"
      },
      "source": [
        "## Solution 11\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    img_size = 64\n",
        "\n",
        "    # The shape of each image in the batch\n",
        "    input_shape = (img_size, img_size, 1)\n",
        "\n",
        "    # Create the model\n",
        "    model = keras.Sequential([\n",
        "        keras.Input(shape=input_shape),\n",
        "        keras.layers.Conv2D(64, 5, activation='relu'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(32, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        loss=keras.losses.BinaryCrossentropy(),\n",
        "        optimizer=\"adam\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    epochs = 10\n",
        "    steps_per_epoch = 20\n",
        "    validation_steps = 4\n",
        "\n",
        "    train_gen = batch_generator(\n",
        "        batch_num=steps_per_epoch * epochs,\n",
        "        batch_size=8,\n",
        "        partition=\"train\",\n",
        "        im_size=img_size\n",
        "    )\n",
        "\n",
        "    val_gen = batch_generator(\n",
        "        batch_num=4 * epochs,\n",
        "        batch_size=2,\n",
        "        partition=\"val\",\n",
        "        im_size=img_size\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        train_gen,\n",
        "        epochs = 10,\n",
        "        steps_per_epoch = steps_per_epoch,\n",
        "        validation_data = val_gen,\n",
        "        validation_batch_size = 2,\n",
        "        validation_steps = validation_steps\n",
        "    )\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PiaXFdfXX6p"
      },
      "source": [
        "**Solution explanation**\n",
        "\n",
        "The generators have been modified appropriately to generate all of the data that is needed for the training period. The number of images in each validation batch has been set to two - one PNEUMONIA and one NORMAL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2jB_pD2XvOk"
      },
      "source": [
        "## Exercise 12 - Saving the model\n",
        "\n",
        "Short exercise: Use [this documentation](https://www.tensorflow.org/tutorials/keras/save_and_load) to save the model as a Keras file.\n",
        "\n",
        "Saving models will allow us to evaluate different models that we train to see how they perform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS6g3IxdXu7i"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9BgeYLaYISb"
      },
      "source": [
        "## Solution 12\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "\tmodel.save('first_model.keras')\n",
        "  ```\n",
        "</details> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1phKnEwWZm_G"
      },
      "source": [
        "# Stage 8 - Evaluating the model\n",
        "\n",
        "Now we have a preliminary trained model, we can start to evaluate its performance on the test dataset. Before we start this process, what is the best way to evaluate a binary classifier?\n",
        "\n",
        "A binary classifer is any predictor that predicts an event that has two possible outcomes. An example includes:\n",
        "\n",
        "1. An ML algorithm that detects an extremely rare disease called Finch's disease (fictional). The prevalence of Finch's is 1 in 1 million.\n",
        "\n",
        "The model's accuracy is 99.8%. When the engineers look closer, they realise that the model is simply predicting \"NORMAL\" for each scan, as there is so little data on Finch's disease.\n",
        "\n",
        "How can we more holistically capture information about the model?\n",
        "\n",
        "## Exercise 13 - Better Metrics\n",
        "\n",
        "Using [this documentation](https://keras.io/api/metrics/) and your knowledge from the seminar, add metrics to the training code from Exercise 11 that will give us greater insight into how the model is actually performing during training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHsXOz1Mca6i"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdGRi-VWcbMY"
      },
      "source": [
        "## Solution 14\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    img_size = 64\n",
        "\n",
        "    # The shape of each image in the batch\n",
        "    input_shape = (img_size, img_size, 1)\n",
        "\n",
        "    # Create the model\n",
        "    model = keras.Sequential([\n",
        "        keras.Input(shape=input_shape),\n",
        "        keras.layers.Conv2D(64, 5, activation='relu'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(32, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        loss=keras.losses.BinaryCrossentropy(),\n",
        "        optimizer=\"adam\",\n",
        "        metrics=[\"accuracy\", keras.metrics.Precision, keras.metrics.Recall, keras.metrics.AUC] # Modified\n",
        "    )\n",
        "\n",
        "    epochs = 10\n",
        "    steps_per_epoch = 20\n",
        "    validation_steps = 4\n",
        "\n",
        "    train_gen = batch_generator(\n",
        "        batch_num=steps_per_epoch * epochs,\n",
        "        batch_size=8,\n",
        "        partition=\"train\",\n",
        "        im_size=img_size\n",
        "    )\n",
        "\n",
        "    val_gen = batch_generator(\n",
        "        batch_num=4 * epochs,\n",
        "        batch_size=2,\n",
        "        partition=\"val\",\n",
        "        im_size=img_size\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        train_gen,\n",
        "        epochs = 10,\n",
        "        steps_per_epoch = steps_per_epoch,\n",
        "        validation_data = val_gen,\n",
        "        validation_batch_size = 2,\n",
        "        validation_steps = validation_steps\n",
        "    )\n",
        "  ```\n",
        "</details> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M1sDvj5dD4Z"
      },
      "source": [
        "**Solution Explanation**\n",
        "\n",
        "This code adds different metrics to the `metrics` array when compiling the model. The AUC gives us information overall information about how well the model works as a classifier, and recall gives us insight into its sensitivity for detecting pnuemonia.\n",
        "\n",
        "In the example of the disease predictor, the recall of a model that predicts NORMAL every time would be **0%**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7KCvX9ffdz_"
      },
      "source": [
        "## Exercise 14 - Better Models\n",
        "\n",
        "Using your knowledge from the first seminar and online sources, modify the model's structure and hyperparameters from Exercise 13 to increase the performance. Try changing the learning rate, batch size, model architecture, and input image resolution. What has the largest effects?\n",
        "\n",
        "Save two versions of the model to allow you to compare them later on in the workbook. *N.B. Keras does not allow you to save the models to keras format when they have custom metrics - use HDF5 format.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYb6WzgjfykT"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv7d-gN2f0p3"
      },
      "source": [
        "## Solution 14 - version 1\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    img_size = 64\n",
        "\n",
        "    # The shape of each image in the batch\n",
        "    input_shape = (img_size, img_size, 1)\n",
        "\n",
        "    # Create the model\n",
        "    model = keras.Sequential([\n",
        "        keras.Input(shape=input_shape),\n",
        "        keras.layers.Conv2D(64, 5, activation='relu'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "        keras.layers.MaxPooling2D(),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(32, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        loss=keras.losses.BinaryCrossentropy(),\n",
        "        optimizer=\"adam\",\n",
        "        metrics=[\"accuracy\", keras.metrics.Precision, keras.metrics.Recall, keras.metrics.AUC] # Modified\n",
        "    )\n",
        "\n",
        "    epochs = 10\n",
        "    steps_per_epoch = 20\n",
        "    validation_steps = 4\n",
        "\n",
        "    train_gen = batch_generator(\n",
        "        batch_num=steps_per_epoch * epochs,\n",
        "        batch_size=8,\n",
        "        partition=\"train\",\n",
        "        im_size=img_size\n",
        "    )\n",
        "\n",
        "    val_gen = batch_generator(\n",
        "        batch_num=4 * epochs,\n",
        "        batch_size=2,\n",
        "        partition=\"val\",\n",
        "        im_size=img_size\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        train_gen,\n",
        "        epochs = 10,\n",
        "        steps_per_epoch = steps_per_epoch,\n",
        "        validation_data = val_gen,\n",
        "        validation_batch_size = 2,\n",
        "        validation_steps = validation_steps\n",
        "    )\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution 14 - version 2\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "  img_size = 128\n",
        "\n",
        "  # The shape of each image in the batch\n",
        "  input_shape = (img_size, img_size, 1)\n",
        "\n",
        "  # Create the model\n",
        "  model = keras.Sequential([\n",
        "      keras.Input(shape=input_shape),\n",
        "      keras.layers.Conv2D(256, 5, activation='relu'),\n",
        "      keras.layers.MaxPooling2D(),\n",
        "      keras.layers.Conv2D(128, 3, activation='relu'),\n",
        "      keras.layers.MaxPooling2D(),\n",
        "      keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "      keras.layers.MaxPooling2D(),\n",
        "      keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "      keras.layers.MaxPooling2D(),\n",
        "      keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "      keras.layers.MaxPooling2D(),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(32, activation='relu'),\n",
        "      keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(\n",
        "      loss=keras.losses.BinaryCrossentropy(),\n",
        "      optimizer=\"adam\",\n",
        "      metrics=[\"accuracy\"] # Modified\n",
        "  )\n",
        "\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 20\n",
        "  validation_steps = 4\n",
        "\n",
        "  train_gen = batch_generator(\n",
        "      batch_num=steps_per_epoch * epochs,\n",
        "      batch_size=8,\n",
        "      partition=\"train\",\n",
        "      im_size=img_size\n",
        "  )\n",
        "\n",
        "  val_gen = batch_generator(\n",
        "      batch_num=4 * epochs,\n",
        "      batch_size=2,\n",
        "      partition=\"val\",\n",
        "      im_size=img_size\n",
        "  )\n",
        "\n",
        "  model.fit(\n",
        "      train_gen,\n",
        "      epochs = epochs,\n",
        "      steps_per_epoch = steps_per_epoch,\n",
        "      validation_data = val_gen,\n",
        "      validation_batch_size = 2,\n",
        "      validation_steps = validation_steps\n",
        "  )\n",
        "\n",
        "  model.save(\"second_model.h5\")\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpoCe7XrufRW"
      },
      "source": [
        "**Solution explanation**\n",
        "\n",
        "Here, we add more convolutional layers prior to flattening the Dense layer. This results in lower-dimensionality of the transition between the convolutional and Dense layers, which makes this layer smaller, and spreads the parameters more evenly throughout the model. We will see if this makes a difference in the next step..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfwgJqIwlFbm"
      },
      "source": [
        "## Exercise 15 - Testing the model on the test dataset\n",
        "\n",
        "Evaluate the model using the test dataset. To do this, build a new function that generates a random sample all of the images in the dataset once, rather than generating random batches. Use your `make_batch` function to help you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vNQM_jSlUNj"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UbQUUHalU_5"
      },
      "source": [
        "## Solution 15\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    sample_num = 10\n",
        "\n",
        "    model = load_model(\"second_model.h5\")\n",
        "    test_paths = get_filepaths(\"test\")\n",
        "    test_x, test_y = make_batch(test_paths, batch_size=sample_num, im_size=128)\n",
        "\n",
        "    predictions = model.predict(test_x)\n",
        "\n",
        "    for pair in zip(predictions, test_y):\n",
        "        print(f\"Model {pair[0][0]}, Truth: {pair[1]}\")\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH9bphqIvAyc"
      },
      "source": [
        "**Solution explanation**\n",
        "\n",
        "We use the `predict` method to generate a NumPy array of predictions from the model. These are continuous values - they have not been thresholded yet to produce **binary**, yes/no predictions. They are compared with each other using Python's `zip` function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYvIVsiOVgmb"
      },
      "source": [
        "## Exercise 16 - Create an ROC curve\n",
        "\n",
        "Use the predictions from the last exercise to create an ROC curve. Use the `metrics` class from `sklearn.metrics` library to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution 16\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    false_pos_rate, true_pos_rate, _ = metrics.roc_curve(test_y, predictions)\n",
        "\n",
        "    plt.plot(false_pos_rate, true_pos_rate)\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "\n",
        "    auc = metrics.auc(false_pos_rate, true_pos_rate)\n",
        "    plt.title(f\"ROC Curve for Pneumonia classifier: AUC = {auc:.3f}\")\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Maoo5Gb5ZxyV"
      },
      "source": [
        "## Exercise 17 - Comparing two models\n",
        "\n",
        "Adapt your code from Exercise 16 into a function which evaluates a model that is passed to it. Use this function to evaluate two of your models and plot their ROC curves on the same axes.\n",
        "\n",
        "Make sure your evaluator can handle the case that models do not have the same input image size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI5JF4LGaLF4"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c9PYqJjaOKk"
      },
      "source": [
        "## Solution 17\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    def model_evaluator(model, sample_size):\n",
        "\n",
        "        # Set the seed so that the evaluation data is the same each time\n",
        "        random.seed(0)\n",
        "\n",
        "        # Determine the input image size from the model\n",
        "        input_size = model.input_shape[1]\n",
        "\n",
        "        test_paths = get_filepaths(\"test\")\n",
        "        test_x, test_y = make_batch(test_paths, batch_size=sample_size, im_size=input_size)\n",
        "\n",
        "        predictions = model.predict(test_x)\n",
        "\n",
        "        false_pos_rate, true_pos_rate, _ = metrics.roc_curve(test_y, predictions)\n",
        "        auc = metrics.auc(false_pos_rate, true_pos_rate)\n",
        "\n",
        "        return false_pos_rate, true_pos_rate, auc\n",
        "\n",
        "    sample_size = 300\n",
        "\n",
        "    model = load_model(\"first_model.keras\")\n",
        "    fpr_1, tpr_1, auc_1 = model_evaluator(model, sample_size)\n",
        "\n",
        "    model = load_model(\"second_model.h5\")\n",
        "    fpr_2, tpr_2, auc_2 = model_evaluator(model, sample_size)\n",
        "\n",
        "    plt.plot(fpr_1, tpr_1, label=f\"AUC: {auc_1:3f}\")\n",
        "    plt.plot(fpr_2, tpr_2, label=f\"AUC: {auc_2:3f}\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.title(f\"ROC Curves for Pneumonia classifiers\")\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMs0NmWad69X"
      },
      "source": [
        "## Exercise 18 - Getting better model performance\n",
        "\n",
        "Using the evaluation plotting tool above, use all of your existing code to experiment with different values for hyperparameters and model architecture to extract the best performance you can.\n",
        "\n",
        "**There will be a prize for the model with the best AUC score within the constraints of the code above!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o13W1kEXd6u2"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STgVF8sonCFo"
      },
      "source": [
        "## Exercise 19 - Visualising these predictions\n",
        "\n",
        "ROC curves sum up the model performance, but we want to see the predictions for the chest XRs that the model is making.\n",
        "\n",
        "Use `pyplot` to display a single image with the prediction from the model. Use a threshold of `0.5` for the model's predictions. Adapt the code from your model evaluator to help you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0LiJAiFodio"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHNIa3uZoaUk"
      },
      "source": [
        "## Solution 19\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    model = load_model(\"second_model.h5\")\n",
        "\n",
        "    test_paths = get_filepaths(\"test\")\n",
        "\n",
        "    input_size = model.input_shape[1]\n",
        "    test_x, test_y = make_batch(test_paths, batch_size=1, im_size=input_size)\n",
        "\n",
        "    predictions = model.predict(test_x)\n",
        "\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(test_x[0], cmap=\"grey\")\n",
        "\n",
        "    labels = [\"Normal\", \"Pneumonia\"]\n",
        "\n",
        "    pred_thresh = predictions[0] > 0.5\n",
        "\n",
        "    true_label = labels[int(test_y[0])]\n",
        "    pred_label = labels[int(pred_thresh[0])]\n",
        "\n",
        "    plt.title(f\"CXR: {true_label}, Predicted: {pred_label}\")\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEjMHVEpmrtI"
      },
      "source": [
        "## Exercise 20 - Calculating metrics from predictions with a threshold\n",
        "\n",
        "Write code that will test a batch of images with the model and work out the **accuracy**, **precision**, and **recall**. Adapt code from previous examples to help you. Try evaluating this with different thresholds - what happens to these metrics?\n",
        "\n",
        "Either calculate the metrics from scratch or use an external library. Use online documentation to help you figure out which library may be most appropriate to use.\n",
        "\n",
        "**Something to consider:** Thresholds should be chosen as appropriate for their task. Most diagnostic algorithms should have a low false negative rate - we don't want to miss important diagnoses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIFvBEH_nFxc"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY67QuwNnGMN"
      },
      "source": [
        "## Solution 20\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show the solution</summary>\n",
        "\n",
        "  ```python\n",
        "    from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "    def print_report(y_test, y_pred, threshold=0.5):\n",
        "\n",
        "        y_pred = y_pred >= threshold\n",
        "\n",
        "        acc_per = accuracy_score(y_test, y_pred) * 100\n",
        "        prec_per = precision_score(y_test, y_pred) * 100\n",
        "        recall_per = recall_score(y_test, y_pred) * 100\n",
        "\n",
        "        print(f\"THRESHOLD: {threshold:.2f}\")\n",
        "        print(f\"Accuracy:  {acc_per:.1f}%\")\n",
        "        print(f\"Precision: {prec_per:.1f}%\")\n",
        "        print(f\"Recall: {recall_per:.1f}%\", end=\"\\n\\n\")\n",
        "\n",
        "\n",
        "    model = load_model(\"second_model.h5\")\n",
        "\n",
        "    test_paths = get_filepaths(\"test\")\n",
        "\n",
        "    samp_num = 300\n",
        "\n",
        "    input_size = model.input_shape[1]\n",
        "    test_x, test_y = make_batch(test_paths, batch_size=samp_num, im_size=input_size)\n",
        "\n",
        "    predictions = model.predict(test_x)\n",
        "\n",
        "    print_report(test_y, predictions, threshold=0.3)\n",
        "    print_report(test_y, predictions, threshold=0.5)\n",
        "    print_report(test_y, predictions, threshold=0.7)\n",
        "  ```\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pBFh_cGxAtl"
      },
      "source": [
        "**Solution Explanation**\n",
        "\n",
        "I have moved the reporting code into a function - this makes it easy to vary the threshold without copying code. The function uses `sklearn`'s methods for calculating these metrics to avoid having to implement them from scratch - don't reinvent the wheel.\n",
        "\n",
        "Notice how the recall decreases as the threshold and accuracy increases - this shows the model being more \"risky\", missing more of the pneumonia in some of the scans."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5bg5qECiJ2b"
      },
      "source": [
        "# Stage 9 - Taking this further\n",
        "\n",
        "There are more techniques that we could use to improve the performance of this model. Some of these are listed below:\n",
        "\n",
        "## Utilising data augmentation\n",
        "\n",
        "This could involve randomly **rotating**, **scaling**, and **flipping** the images - *refer for to the seminar for a reminder.*\n",
        "\n",
        "This would be fairly easy to implement in the `crop_and_scale` function.\n",
        "\n",
        "**Extension exercise:** Modify the code to augment the training data when training the model.\n",
        "\n",
        "## Identifying different types of pneumonia\n",
        "\n",
        "You may have noticed that the filenames of the images contain **additional labels** - `bacterial` and `viral`. The model could be modified to have **3 output neurons** rather than just 1, and **could be used to differentiate** between normal, bacterial pneumonia, and viral pneumonia.\n",
        "\n",
        "**Extension exercise:** Modify the model and training code to differentiate between normal scans, scans with viral pneumonia, and scans with bacterial pneumonia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_zzaQGTssAq"
      },
      "source": [
        "# Conclusions and Further Practice\n",
        "\n",
        "We've reached the end of the AI workbook for DAIM - we hope that you have enjoyed working through it and learning how to build an ML algorithm from scratch.\n",
        "\n",
        "Further exercises that you could do with this dataset include:\n",
        "\n",
        "1. The suggestions from Stage 9, including adding data augmentation and identifying different types of pneumonia\n",
        "2. Refactoring all of your code from this workbook into a single script.\n",
        "3. Creating more visualisations - can you plot a confusion matrix?\n",
        "4. Adapting another algorithm for this dataset using the data preprocessing we've used.\n",
        "    - A good target for this is [this tutorial](https://keras.io/examples/generative/vae/) which shows you how to make a **variational autoencoder**\n",
        "    - These algorithms compress images into a **low dimensional space** that sums up their characteristics, and then **reconstructs** them.\n",
        "    - These can be used to **generate** data.\n",
        "\n",
        "Please let us know if you have any **questions** or **feedback** about any of the content in this workbook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
